<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron and Deepak Pathak and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 17px; /* 19 */
    font-weight: 600 /* 1000 */
  }
  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 600 /* 800 */
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 38px;
    font-weight: 400
  }
  .ImageBorder
  {
      border-width: 1px;
      border-color: Black;
  }
  </style>
  <link rel="shortcut icon" href="images/logo.jpg">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Xinyuan Yan</title>
  <meta name="Xinyuan Yan's Homepage" http-equiv="Content-Type" content="Xinyuan Yan's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-XXXXX-Y', 'auto');
    ga('send', 'pageview');
    </script>
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>
 
<body>
<table width="900" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <pageheading>Xinyuan Yan 「闫鑫源」</pageheading><br>
  </p>

  <tr>
    <td width="30%" valign="top"><a href="images/XinyuanYan-2024.jpg"><img src="images/XinyuanYan-2024.jpg" width="100%" style="border-radius:15px"></a>
    <p align=center>
    | <a href="data/Xinyuan Yan_CV_20250730.pdf">CV</a> |
    <a href="mailto:yan1075783878@gmail.com">Email</a> |
    <a href="https://scholar.google.com/citations?user=D_Ay8fQAAAAJ&hl=en-US">Google Scholar</a> |
    <br/>
    | <a href="https://github.com/Naclzno">Github</a> | 
    <!-- <a href="https://www.linkedin.com/in/tairan-he-41a904294/">LinkedIn</a> |
    <a href="https://space.bilibili.com/14145636">Bilibili</a> |  -->
    <!-- </p>
    <p align="center" style="margin-top:-8px;"><iframe id="twitter-widget-0" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" class="twitter-follow-button twitter-follow-button-rendered" style="position: static; visibility: visible; width: 156px; height: 20px;" title="Twitter Follow Button" src="https://platform.twitter.com/widgets/follow_button.2f70fb173b9000da126c79afe2098f02.en.html#dnt=false&amp;id=twitter-widget-0&amp;lang=en&amp;screen_name=TairanHe99&amp;show_count=false&amp;show_screen_name=true&amp;size=m&amp;time=1706734206165" data-screen-name=""></iframe><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p> -->
    </td>
    <td width="70%" valign="top" align="justify">
      <p>I am a third-year master's student at the <a href="https://chxy.bucea.edu.cn/">School of Geomatics and Urban Spatial Information</a> at <a href="https://english.bucea.edu.cn/">Beijing University of Civil Engineering and Architecture</a>, advised by <a href="https://chxy.bucea.edu.cn/szdw/xnjs/axs/H/854c3e0bbdb241ec8f9b294cbfd2b723.htm"> He Huang</a> and <a href="https://chxy.bucea.edu.cn/szdw/xnjs/axs/Y/401d2500f1434a2f9c2966e6a6aa3988.htm"> Junxing Yang</a>. 
        <!-- I am also a member of <a href="https://research.nvidia.com/labs/gear/">NVIDIA GEAR group </a> led by <a href="https://jimfan.me/"> Jim Fan</a> and <a href="https://yukezhu.me/"> Yuke Zhu</a>. -->
      </p>
      <p>I received my Bachelor's degree in surveying and mapping at <a href="https://www.ncwu.edu.cn/index.htm"> North China University of Water Resources and Electric Power</a>.
        <!-- , advised by <a href="http://wnzhang.net"> Weinan Zhang</a>. I also spent time at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/"> Microsoft Research Asia</a>. -->
      </p>
      <!-- <p>Goal: challenge conventional notions of what robots can achieve, develop robots that improves everyone's life. Focus: developing intelligent robots being able to do useful tasks with <u>intelligence, generalizability, agility and safety</u>. Method: learning-based methods that scale with the computation and data. Robots: Mobile robots, legged robots, robotic manipulators, and humanoid robots.
      </p> -->
      <p><strong>Goal:</strong> Autonomous vehicles can operate safely under adverse weather conditions.</p>
      <p><strong>Focus:</strong> The challenges faced by autonomous driving perception systems <u>under adverse weather conditions</u>.</p>
      <p><strong>Current research fields:</strong> Point cloud denoising, point cloud semantic segmentation, and 3D occupancy prediction.</p>
      <!-- <p><strong>Robots:</strong> I love working on humanoids and aim to make them capable of doing everything I can do—and more.</p> -->
      <p>Email:  yan1075783878@gmail.com </p>
      <p>I am currently searching for and applying to PhD programs. If you have any good opportunities related to PhD studies or internships, please feel free to contact me via email.
     </p>
    </td>
  </tr>
</table>

<hr/>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;News</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
      <ul>
        <!-- <li>[12/2024] Received NVIDIA Graduate Fellowship. Thanks, NVIDIA!</li>  -->
        <li>[11/2024] Received China National Graduate Student Scholarship (top 8% students in BUCEA). Thanks, BUCEA!</li> 
        <!-- <li>[07/2024] <a href="https://agile-but-safe.github.io/">ABS</a> is selected as the <a href="https://roboticsconference.org/2024/program/awards/">Outstanding Student Paper Award Finalist at RSS 2024</a>!</li>
        <li>[04/2024] Invited talk at <a href="https://www.techbeat.net/talk-info?id=864">TechBeat</a>.</li>  -->
        <!-- <a href="javascript:toggleblock('news')">---- show more ----</a>
        <div id="news" style="display:none">
          <li>[11/2024] Received CMU RI Presidential Fellowship. Thanks, CMU!</li> 
        </div> -->

      </ul>
    </td>
  </tr>
  
</table>


<hr/>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Publications</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">

<!-- Place this tag in your head or just before your close body tag. -->
<script async defer src="https://buttons.github.io/buttons.js"></script>


  <tr>
    <td width="40%" valign="top" align="center">
      <a href="https://doi.org/10.5194/isprs-archives-XLVIII-G-2025-921-2025">
          <img src="images/SnowSTNet/picture.jpg" alt="sym" width="80%" style="padding-top:0px; padding-bottom:0px; border-radius:15px; height: auto;">
      </a>
    </td>
    <td width="60%" valign="top">
      <p><a href="https://doi.org/10.5194/isprs-archives-XLVIII-G-2025-921-2025" id="SnowSTNet">
      <heading>SnowSTNet: A Spatial-Temporal LiDAR Point Cloud Denoising Network for Autonomous Driving in Snowy Weather</heading></a><br>
      Yida Li, Xinyuan Yan, He Huang, Yu Liang, Yidan Zhang, Junxing Yang*<br>
      ISPRS Geospatial Week 2025<br>
      </p>

      <div class="paper" id="snowstnet">
      <a href="https://isprs-archives.copernicus.org/articles/XLVIII-G-2025/921/2025/isprs-archives-XLVIII-G-2025-921-2025.pdf">pdf</a> |
      <a href="javascript:toggleblock('snowstnet_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('snowstnet')" class="togglebib">bibtex</a> 
      <!-- <a href="https://github.com/Naclzno/LIDSOR">code</a> 
      <iframe src="https://ghbtns.com/github-btn.html?user=Naclzno&repo=LIDSOR&type=star&count=true"
              frameborder="0" scrolling="0" width="100px" height="20px"
              style="vertical-align: middle; margin-left: 5px;">
      </iframe> -->
      <p align="justify"> <i id="snowstnet_abs">Autonomous vehicles perceive their surroundings through sensors such as LiDAR. However, snowflakes are distributed within the detection range of LiDAR sensors in snowy weather, generating noise points that compromise the sensor's detection performance. To mitigate this issue, we propose SnowSTNet, a point cloud denoising network that removes snowflake noise from LiDAR point clouds. In SnowSTNet, we adopt a two-branch network structure that encodes information in both spatial and temporal dimensions, and inputs the features obtained from the spatial branch into the temporal branch as guidance. We conducted comparative experiments on the SnowyKITTI dataset, and the results show that our method significantly outperforms others, achieving an MIoU of 97.19%. The proposed SnowSTNet ensures the reliable operation of self-driving vehicles in snowy weather and promotes the widespread application of autonomous driving technology in complex environments.</i></p>

<pre xml:space="preserve">
@Article{isprs-archives-XLVIII-G-2025-921-2025,
AUTHOR = {Li, Y. and Yan, X. and Huang, H. and Liang, Y. and Zhang, Y. and Yang, J.},
TITLE = {SnowSTNet: A Spatial-Temporal LiDAR Point Cloud Denoising Network for Autonomous Driving in Snowy Weather},
JOURNAL = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
VOLUME = {XLVIII-G-2025},
YEAR = {2025},
PAGES = {921--927},
URL = {https://isprs-archives.copernicus.org/articles/XLVIII-G-2025/921/2025/},
DOI = {10.5194/isprs-archives-XLVIII-G-2025-921-2025}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="40%" valign="top" align="center">
      <a href="https://isprs-archives.copernicus.org/articles/XLVIII-G-2025/1733/2025/">
          <img src="images/TADNet/picture.jpg" alt="sym" width="80%" style="padding-top:0px; padding-bottom:0px; border-radius:15px; height: auto;">
      </a>
    </td>
    <td width="60%" valign="top">
      <p><a href="https://isprs-archives.copernicus.org/articles/XLVIII-G-2025/1733/2025/" id="TADNet">
      <heading>TADNet: A Time and Attention-Based Point Cloud Denoising Network for Autonomous Driving in Adverse Weather</heading></a><br>
      Yidan Zhang, He Huang, Xinyuan Yan, Yu Liang, Yida Li, Junxing Yang*<br>
      ISPRS Geospatial Week 2025<br>
      </p>

      <div class="paper" id="tadnet">
      <a href="https://isprs-archives.copernicus.org/articles/XLVIII-G-2025/1733/2025/isprs-archives-XLVIII-G-2025-1733-2025.pdf">pdf</a> |
      <a href="javascript:toggleblock('tadnet_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('tadnet')" class="togglebib">bibtex</a> 
      <!-- <a href="https://github.com/Naclzno/LIDSOR">code</a> 
      <iframe src="https://ghbtns.com/github-btn.html?user=Naclzno&repo=LIDSOR&type=star&count=true"
              frameborder="0" scrolling="0" width="100px" height="20px"
              style="vertical-align: middle; margin-left: 5px;">
      </iframe> -->
      <p align="justify"> <i id="tadnet_abs">Lidar technology is widely used in the field of autonomous driving by virtue of its high precision. However, under special weather conditions such as rain, snow, fog, etc., suspended particles in the air can contaminate the point cloud data collected by LIDAR, which leads to a significant performance degradation of the vehicle sensing system and increases the driving safety risk. To address this problem, we propose A Time and Attention-Based Point Cloud Denoising Network for Autonomous Driving in Adverse Weather (TADNet). The method is based on the 3D-OutDet network with the addition of Convolutional Block Attention Module (CBAM), which highlights important features and suppresses minor ones. The original ResNet base network architecture is changed to Temporal-Bottleneck ResNet (TB-ResNet) to improve the network's ability to recognize rain, snow and fog noise. We conducted comparative experiments between the TADNet method proposed in this paper and the filter-based point cloud denoising method and the deep learning-based point cloud denoising method. The experimental results show that the denoising effect of TADNet in three kinds of bad weather, namely rain, snow and fog, is better than other methods, which can remove different kinds of noise with different intensities and retain the environmental features, and has the best performance of IoU and MIoU in all kinds of weather conditions.</i></p>

<pre xml:space="preserve">
@Article{isprs-archives-XLVIII-G-2025-1733-2025,
AUTHOR = {Zhang, Y. and Huang, H. and Yan, X. and Liang, Y. and Li, Y. and Yang, J.},
TITLE = {TADNet: A Time and Attention-Based Point Cloud Denoising Network for Autonomous Driving in Adverse Weather},
JOURNAL = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
VOLUME = {XLVIII-G-2025},
YEAR = {2025},
PAGES = {1733--1739},
URL = {https://isprs-archives.copernicus.org/articles/XLVIII-G-2025/1733/2025/},
DOI = {10.5194/isprs-archives-XLVIII-G-2025-1733-2025}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="40%" valign="top" align="center">
      <a href="https://ieeexplore.ieee.org/document/10832503">
          <img src="images/AdverseNet/graphical abstract.jpg" alt="sym" width="80%" style="padding-top:0px; padding-bottom:0px; border-radius:15px; height: auto;">
      </a>
    </td>
    <td width="60%" valign="top">
      <p><a href="https://ieeexplore.ieee.org/document/10832503" id="AdverseNet">
      <heading>AdverseNet: A LiDAR Point Cloud Denoising Network for Autonomous Driving in Rainy, Snowy, and Foggy Weather</heading></a><br>
      Xinyuan Yan, Junxing Yang*, Yu Liang, Yanjie Ma, Yida Li, He Huang<br>
      IEEE Sensors Journal 2025<br>
      </p>

      <div class="paper" id="adversenet">
      <!-- <a href="data/TOR.pdf">pdf</a> | -->
      <a href="javascript:toggleblock('adversenet_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('adversenet')" class="togglebib">bibtex</a> |
      <a href="https://github.com/Naclzno/AdverseNet">code</a> 
      <iframe src="https://ghbtns.com/github-btn.html?user=Naclzno&repo=AdverseNet&type=star&count=true"
              frameborder="0" scrolling="0" width="100px" height="20px"
              style="vertical-align: middle; margin-left: 5px;">
      </iframe>
      <p align="justify"> <i id="adversenet_abs">In the field of autonomous driving, a pressing issue is how to enable LiDAR to accurately perceive the 3-D environment around the vehicle without being affected by rain, snow, and fog. Specifically, rain, snow, and fog can be present within the LiDAR’s detection range and create noise points. To address this problem, we propose a unified denoising network, AdverseNet, for adverse weather point clouds, which is capable of removing noise points caused by rain, snow, and fog from LiDAR point clouds. In AdverseNet, we adopt the cylindrical triperspective view (CTPV) representation for point clouds and employ a two-stage training strategy. In the first training stage, generic features of rain, snow, and fog noise points are learned. In the second training stage, specific weather features are learned. We conducted comparative experiments on the DENSE dataset and the SnowyKITTI dataset, and the results show that the performance of our method on both datasets is significantly improved compared to other methods, with the Mean Intersection over Union (MIoU) reaching 94.67% and 99.33%, respectively. Our proposed AdverseNet enhances the LiDAR sensing capability in rain, snow, and fog, ensuring the safe operation of autonomous vehicles in adverse weather conditions. The source code is available at https://github.com/Naclzno/AdverseNet.</i></p>

<pre xml:space="preserve">
  @ARTICLE{10832503,
    author={Yan, Xinyuan and Yang, Junxing and Liang, Yu and Ma, Yanjie and Li, Yida and Huang, He},
    journal={IEEE Sensors Journal}, 
    title={AdverseNet: A LiDAR Point Cloud Denoising Network for Autonomous Driving in Rainy, Snowy, and Foggy Weather}, 
    year={2025},
    volume={25},
    number={5},
    pages={8950-8961},
    doi={10.1109/JSEN.2024.3505234}}
</pre>
      </div>
    </td>
  </tr>



  <tr>
    <td width="40%" valign="top" align="center">
      <a href="https://ieeexplore.ieee.org/document/10418150">
          <img src="images/TOR/abstract.png" alt="sym" width="80%" style="padding-top:0px; padding-bottom:0px; border-radius:15px; height: auto;">
      </a>
    </td>
    <td width="60%" valign="top">
      <p><a href="https://ieeexplore.ieee.org/document/10418150" id="TOR">
      <heading>Denoising Framework Based on Multi-frame Continuous Point Clouds for Autonomous Driving LiDAR in Snowy Weather</heading></a><br>
      Xinyuan Yan, Junxing Yang, Xinyu Zhu, Yu Liang, He Huang*<br>
      IEEE Sensors Journal 2024<br>
      </p>

      <div class="paper" id="tor">
      <a href="data/TOR.pdf">pdf</a> |
      <a href="javascript:toggleblock('tor_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('tor')" class="togglebib">bibtex</a> |
      <a href="https://github.com/Naclzno/TOR">code</a> 
      <iframe src="https://ghbtns.com/github-btn.html?user=Naclzno&repo=TOR&type=star&count=true"
              frameborder="0" scrolling="0" width="100px" height="20px"
              style="vertical-align: middle; margin-left: 5px;">
      </iframe>
      <p align="justify"> <i id="tor_abs">Adverse weather conditions are one of the long-tailed problems facing autonomous driving. Solving the problem of autonomous driving operation in adverse weather conditions is an important challenge for realizing advanced autonomous driving. To enhance the LiDAR perception capability in snowy weather for autonomous driving, this study proposes a denoising method for multiframe continuous point clouds. The core concept of this method is to allow ordered objects (e.g., stationary objects on the ground) to strengthen each other while allowing disordered objects (e.g., snow) to weaken each other. This is done by first selecting three consecutive frames of the point cloud as a denoising unit and then removing the ground points from each frame of the point cloud. After that, the point clouds from the first two frames are used as the source point clouds, and the point cloud from the third frame is used as the target point cloud for point cloud registration. Finally, the time outlier removal (TOR) filter proposed in this article combined with the entropy weight method (EWM) is utilized for denoising. The experimental results show that the performance of the method proposed in this article exceeds the existing methods. In addition, the method in this article not only removes the disordered snowflakes in the air, but also removes some other disordered noise points (e.g., the ghosting of the stationary objects), which provides an advantageous guarantee for the realization of automatic driving in snowy weather.</i></p>

<pre xml:space="preserve">
  @article{yan2024denoising,
    title={Denoising Framework Based on Multi-frame Continuous Point Clouds for Autonomous Driving LiDAR in Snowy Weather},
    author={Yan, Xinyuan and Yang, Junxing and Zhu, Xinyu and Liang, Yu and Huang, He},
    journal={IEEE Sensors Journal},
    year={2024},
    publisher={IEEE}
  }
</pre>
      </div>
    </td>
  </tr>


  <tr>
    <td width="40%" valign="top" align="center">
      <a href="https://isprs-archives.copernicus.org/articles/XLVIII-1-W2-2023/733/2023/">
          <img src="images/LIDSOR/picture.gif" alt="sym" width="80%" style="padding-top:0px; padding-bottom:0px; border-radius:15px; height: auto;">
      </a>
    </td>
    <td width="60%" valign="top">
      <p><a href="https://isprs-archives.copernicus.org/articles/XLVIII-1-W2-2023/733/2023/" id="LIDSOR">
      <heading>LIDSOR: A filter for removing rain and snow noise points from LiDAR point clouds in rainy and snowy weather</heading></a><br>
      He Huang, Xinyuan Yan, Junxing Yang*, Yuming Cao, Xin Zhang<br>
      ISPRS Geospatial Week 2023<br>
      </p>

      <div class="paper" id="lidsor">
      <a href="https://isprs-archives.copernicus.org/articles/XLVIII-1-W2-2023/733/2023/isprs-archives-XLVIII-1-W2-2023-733-2023.pdf">pdf</a> |
      <a href="javascript:toggleblock('lidsor_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('lidsor')" class="togglebib">bibtex</a> |
      <a href="https://github.com/Naclzno/LIDSOR">code</a> 
      <iframe src="https://ghbtns.com/github-btn.html?user=Naclzno&repo=LIDSOR&type=star&count=true"
              frameborder="0" scrolling="0" width="100px" height="20px"
              style="vertical-align: middle; margin-left: 5px;">
      </iframe>
      <p align="justify"> <i id="lidsor_abs">As autonomous driving technology advances, ensuring the system's safety in rain and snow has emerged as a pivotal research topic. In rainy and snowy weather, rain and snow can generate noise points within the point cloud captured by the Light Detection and Ranging (LiDAR), significantly impeding the LiDAR's sensing capability. To address this problem, we first manually label the point cloud data gathered in rain and snow, categorizing all points into noise points and non-noise points. Subsequently, we analyze the intensity and spatial distribution characteristics of the rain and snow noise points and employ the gamma distribution curve to illustrate the spatial distribution characteristics of these noise points. Finally, we propose a Low-Intensity Dynamic Statistical Outlier Removal (LIDSOR) filter, an enhancement of the existing Dynamic Statistical Outlier Removal (DSOR) filter. Experimental results suggest that the LIDSOR filter can effectively eliminate rain and snow noise points while preserving more environmental feature points. Additionally, it consumes fewer computational resources. The filter we propose in this paper significantly contributes to the safe operation of the autonomous driving system in diverse complex environments.</i></p>

<pre xml:space="preserve">
  @article{huang2023lidsor,
    title={LIDSOR: A filter for removing rain and snow noise points from LiDAR point clouds in rainy and snowy weather},
    author={Huang, He and Yan, Xinyuan and Yang, Junxing and Cao, Yuming and Zhang, Xin},
    journal={The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
    volume={48},
    pages={733--740},
    year={2023},
    publisher={Copernicus GmbH}
  }
</pre>
      </div>
    </td>
  </tr>


</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Projects</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">

  <!-- <tr>
    <td width="40%" valign="top" align="center">
      <a href="https://www.bilibili.com/video/BV1Rp4y187ZJ">
          <img src="images/wkfg/wkfgicon.png" alt="sym" width="70%" style="padding-top:0px; padding-bottom:0px; border-radius:15px; height: auto;">
      </a>
    </td>
    <td width="60%" valign="top">
      <p><a href="https://www.bilibili.com/video/BV1Rp4y187ZJ" id="AUTOCOST">
      <heading>SJTU Anonymous Forum 「无可奉告」</heading></a><br>
      </p>

      <div class="paper" id="autocost">
      <a href="https://github.com/TairanHe/SJTU-Anonymous_Forum"> Android Code</a> |
      <a href="https://github.com/oscardhc/Forum"> iOS Code</a> |
      <a href="http://wukefenggao.cn"> Project Page</a> |
      <a href="https://www.bilibili.com/video/BV1Rp4y187ZJ"> Farewell Video</a>

      <p align="justify"> <i id="wkfg_abs">A carefree forum platform for SJTUers sharing and talking with anonymous identity. More than <font color="red"><em><strong>10000+</strong></em></font> users used「无可奉告」in the SJTU campus.</i></p>

      </div>
    </td>
  </tr> -->

  <tr>
    <td width="40%" valign="top" align="center">
      <a href="https://www.proceedings.com/076061-0020.html">
          <img src="images/Panoramic Roaming System/picture.png" alt="sym" width="80%" style="padding-top:0px; padding-bottom:0px; border-radius:15px; height: auto;">
      </a>
    </td>
    <td width="60%" valign="top">
      <p><a href="https://www.proceedings.com/076061-0020.html" id="PRS">
      <heading>Research on the Production of an Integrated Air-Ground Panoramic Roaming System: A Case Study of Beijing University of Civil Engineering and Architecture</heading></a><br>
      Yida Li, Yucheng Liu, Xinyuan Yan, Dinglong Yu, Junxing Yang*<br>
      ISPM 2024<br>
      </p>

      <div class="paper" id="prs">
      <!-- <a href="data/Panoramic Roaming System/Research on the Production of an Integrated Air-Ground Panoramic Roaming System A Case Study of Beijing University of Civil Engineering and Architecture.pdf">pdf</a> | -->
      <a href="javascript:toggleblock('prs_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('prs')" class="togglebib">bibtex</a> 

      <p align="justify"> <i id="prs_abs">With the advancement of image processing technology, buildings, streets, and other scenes can now be displayed in 3D panoramas. This study employs 3D panoramic roaming technology, based on the spherical panoramic image stitching method, to achieve integrated air-ground panoramic roaming for the Daxing Campus of Beijing University of Civil Engineering and Architecture. The process of data preprocessing and panoramic roaming production is meticulously documented. The specific functionalities realized in this study include the interaction between aerial and ground scenes, seamless roaming of the campus ground scenes, linkage between panoramic roaming and the navigation map, synchronization of the navigation map to display site points and radar sector positions, and the integration of the roaming system into the server.</i></p>

<pre xml:space="preserve">
  @article{Yan2024,
    title = {Research on the Production of an Integrated Air-Ground Panoramic Roaming System: A Case Study of Beijing University of Civil Engineering and Architecture},
    journal = {12th International Symposium on Project Management, ISPM 2024},
    year = {2024},
    volume = {1},
    pages = {146-154},
    author = {Li, Yida and Liu, Yucheng and Yan, Xinyuan and Yu, Dinglong and Yang, Junxing}
  }
</pre>
      </div>
    </td>
  </tr>


</table>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Reviewer Service</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
  <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      Optics and Laser Technology 2025
      <br>
      Scientific Reports 2025
      <br>  
      IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing <b>(JSTARS)</b> 2025
      <br>
      IEEE Transactions on Intelligent Vehicles <b>(T-IV)</b> 2024
      </p>
    </td>
  </tr>
</table>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Internships</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
  <!-- <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">

      International Conference on Machine Learning <b>(ICML)</b>, 2024
      <br>
      International Conference on Learning Representations <b>(ICLR)</b>, 2024
      <br>
      IEEE Conference on Decision and Control <b>(CDC)</b>, 2023
      <br>  
      Conference on Neural Information Processing Systems <b>(NeurIPS)</b>, 2023
      <br>
      Learning for Dynamics & Control Conference <b>(L4DC)</b> 2023
      <br>
      AAAI Conference on Artificial Intelligence <b>(AAAI)</b> 2023, 2024, 2025
      <br>
      Conference on Robot Learning <b>(CoRL)</b> 2022, 2023, 2024
      </p>
    </td>
  </tr> -->
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody>
      <tr>
          <td style="padding:0px">
              <br>
              <br>
              <div>
                  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=500&t=tt&d=qp6cFmbqQL-6quJXDDbPGkxcnUSYDA9mEocd51F9Mlg&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>
                  <!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=a&t=tt&d=qp6cFmbqQL-6quJXDDbPGkxcnUSYDA9mEocd51F9Mlg&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script> -->
                  <!-- <a target="_top" href="http://clustrmaps.com/site/1acpn?utm_source=widget&amp;utm_campaign=widget_ctr" id="clustrmaps-widget-v2" class="clustrmaps-map-control" style="width: 300px;">
-->                               </div>
          </td>
      </tr>
  </tbody>
</table>








<hr/>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="2">
    <tr><td><br><p align="right">
    Website template from <a href="https://tairanhe.com/">here</a>
    <!-- Website template from <a href="http://www.cs.berkeley.edu/~barron/">here</a> and <a href="http://www.cs.cmu.edu/~dpathak/">here</a> -->
    </font></p></td></tr>
</table>

  </td></tr>
</table>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>

<script xml:space="preserve" language="JavaScript">
  hideblock('snowstnet_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('tadnet_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('adversenet_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('tor_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('lidsor_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('prs_abs');
</script>
</body>

</html>
